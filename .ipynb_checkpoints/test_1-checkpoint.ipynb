{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fed0ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import pdb\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from utils.utils import generate_split, nth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdff9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = 'dataset_csv/fungal_vs_nonfungal.csv'\n",
    "csv_path = 'dataset_csv/tumor_vs_normal_dummy_clean.csv'\n",
    "shuffle = False\n",
    "print_info = True\n",
    "label_dict = {'normal_tissue':0, 'tumor_tissue':1}\n",
    "# label_dict = {'nonfungal':0, 'fungal':1}\n",
    "patient_strat=False\n",
    "ignore=[]\n",
    "\n",
    "seed = 7\n",
    "filter_dict = {}\n",
    "label_col = 'label'\n",
    "patient_voting = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60bd1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_data_prep(patient_voting='max'):\n",
    "    patients = np.unique(np.array(slide_data['case_id'])) # get unique patients\n",
    "    patient_labels = []\n",
    "\n",
    "    for p in patients:\n",
    "        locations = slide_data[slide_data['case_id'] == p].index.tolist()\n",
    "        assert len(locations) > 0\n",
    "        label = slide_data['label'][locations].values\n",
    "        if patient_voting == 'max':\n",
    "            label = label.max() # get patient label (MIL convention)\n",
    "        elif patient_voting == 'maj':\n",
    "            label = stats.mode(label)[0]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        patient_labels.append(label)\n",
    "\n",
    "    patient_data = {'case_id':patients, 'label':np.array(patient_labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7216d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_ids_prep():\n",
    "    # store ids corresponding each class at the patient or case level\n",
    "    patient_cls_ids = [[] for i in range(num_classes)]\n",
    "    for i in range(num_classes):\n",
    "        patient_cls_ids[i] = np.where(patient_data['label'] == i)[0]\n",
    "\n",
    "    # store ids corresponding each class at the slide level\n",
    "    slide_cls_ids = [[] for i in range(num_classes)]\n",
    "    for i in range(num_classes):\n",
    "        slide_cls_ids[i] = np.where(slide_data['label'] == i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a113c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filter_dict={}):\n",
    "    if len(filter_dict) > 0:\n",
    "        filter_mask = np.full(len(df), True, bool)\n",
    "        # assert 'label' not in filter_dict.keys()\n",
    "        for key, val in filter_dict.items():\n",
    "            mask = df[key].isin(val)\n",
    "            filter_mask = np.logical_and(filter_mask, mask)\n",
    "        df = df[filter_mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2a7a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_prep(data, label_dict, ignore, label_col):\n",
    "    if label_col != 'label':\n",
    "        data['label'] = data[label_col].copy()\n",
    "\n",
    "    mask = data['label'].isin(ignore)\n",
    "    data = data[~mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    for i in data.index:\n",
    "        key = data.loc[i, 'label']\n",
    "        data.at[i, 'label'] = label_dict[key]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01665eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generic_MIL_Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9416/584693071.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mGeneric_Split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneric_MIL_Dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslide_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_h5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslide_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Generic_MIL_Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class Generic_Split(Generic_MIL_Dataset):\n",
    "    def __init__(self, slide_data, data_dir=None, num_classes=2):\n",
    "        self.use_h5 = False\n",
    "        self.slide_data = slide_data\n",
    "        self.data_dir = data_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.slide_cls_ids = [[] for i in range(self.num_classes)]\n",
    "        for i in range(self.num_classes):\n",
    "            self.slide_cls_ids[i] = np.where(self.slide_data['label'] == i)[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slide_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_from_df(all_splits, split_key='train'):\n",
    "    split = all_splits[split_key]\n",
    "    split = split.dropna().reset_index(drop=True)\n",
    "\n",
    "    if len(split) > 0:\n",
    "        mask = slide_data['slide_id'].isin(split.tolist())\n",
    "        df_slice = slide_data[mask].reset_index(drop=True)\n",
    "        split = Generic_Split(df_slice, data_dir=data_dir, num_classes=num_classes)\n",
    "    else:\n",
    "        split = None\n",
    "\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93cc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_splits(from_id=True, csv_path=None):\n",
    "\n",
    "\n",
    "    if from_id:\n",
    "        if len(train_ids) > 0:\n",
    "            train_data = slide_data.loc[train_ids].reset_index(drop=True)\n",
    "            train_split = Generic_Split(train_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            train_split = None\n",
    "\n",
    "        if len(val_ids) > 0:\n",
    "            val_data = slide_data.loc[val_ids].reset_index(drop=True)\n",
    "            val_split = Generic_Split(val_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            val_split = None\n",
    "\n",
    "        if len(self.test_ids) > 0:\n",
    "            test_data = slide_data.loc[test_ids].reset_index(drop=True)\n",
    "            test_split = Generic_Split(test_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            test_split = None\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert csv_path\n",
    "        all_splits = pd.read_csv(csv_path, dtype=slide_data['slide_id'].dtype)  # Without \"dtype=self.slide_data['slide_id'].dtype\", read_csv() will convert all-number columns to a numerical type. Even if we convert numerical columns back to objects later, we may lose zero-padding in the process; the columns must be correctly read in from the get-go. When we compare the individual train/val/test columns to self.slide_data['slide_id'] in the get_split_from_df() method, we cannot compare objects (strings) to numbers or even to incorrectly zero-padded objects/strings. An example of this breaking is shown in https://github.com/andrew-weisman/clam_analysis/tree/main/datatype_comparison_bug-2021-12-01.\n",
    "        train_split = get_split_from_df(all_splits, 'train')\n",
    "        val_split = get_split_from_df(all_splits, 'val')\n",
    "        test_split = get_split_from_df(all_splits, 'test')\n",
    "\n",
    "    return train_split, val_split, test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfa5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f803a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(set(label_dict.values()))\n",
    "train_ids, val_ids, test_ids = (None, None, None)\n",
    "data_dir = None\n",
    "if not label_col:\n",
    "\tlabel_col = 'label'\n",
    "label_col = label_col\n",
    "\n",
    "slide_data = pd.read_csv(csv_path)\n",
    "slide_data = filter_df(slide_data, filter_dict)\n",
    "slide_data = df_prep(slide_data, label_dict, ignore, label_col)\n",
    "print(slide_data)\n",
    "\n",
    "###shuffle data\n",
    "if shuffle:\n",
    "\tnp.random.seed(seed)\n",
    "\tnp.random.shuffle(slide_data)\n",
    "\n",
    "slide_data = slide_data\n",
    "\n",
    "patient_data_prep(patient_voting)\n",
    "cls_ids_prep()\n",
    "\n",
    "if print_info:\n",
    "\tsummarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe96183",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_datasets = slide_data\n",
    "splits = [split_datasets[i].slide_data['slide_id'] for i in range(len(split_datasets))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "clam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
