{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4642ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import pdb\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from utils.utils import generate_split, nth\n",
    "\n",
    "from datasets.dataset_generic import Generic_WSI_Classification_Dataset, Generic_MIL_Dataset, save_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f78c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = 'dataset_csv/fungal_vs_nonfungal.csv'\n",
    "csv_path = 'dataset_csv/tumor_vs_normal_dummy_clean.csv'\n",
    "shuffle = False\n",
    "print_info = True\n",
    "label_dict = {'normal_tissue':0, 'tumor_tissue':1}\n",
    "# label_dict = {'nonfungal':0, 'fungal':1}\n",
    "patient_strat=False\n",
    "ignore=[]\n",
    "\n",
    "seed = 7\n",
    "filter_dict = {}\n",
    "label_col = 'label'\n",
    "patient_voting = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8ffd7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_data_prep(patient_voting='max'):\n",
    "    patients = np.unique(np.array(slide_data['case_id'])) # get unique patients\n",
    "    patient_labels = []\n",
    "\n",
    "    for p in patients:\n",
    "        locations = slide_data[slide_data['case_id'] == p].index.tolist()\n",
    "        assert len(locations) > 0\n",
    "        label = slide_data['label'][locations].values\n",
    "        if patient_voting == 'max':\n",
    "            label = label.max() # get patient label (MIL convention)\n",
    "        elif patient_voting == 'maj':\n",
    "            label = stats.mode(label)[0]\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        patient_labels.append(label)\n",
    "\n",
    "    patient_data = {'case_id':patients, 'label':np.array(patient_labels)}\n",
    "    return patient_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "65b010a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_ids_prep(patient_data):\n",
    "    # store ids corresponding each class at the patient or case level\n",
    "    patient_cls_ids = [[] for i in range(num_classes)]\n",
    "    for i in range(num_classes):\n",
    "        patient_cls_ids[i] = np.where(patient_data['label'] == i)[0]\n",
    "\n",
    "    # store ids corresponding each class at the slide level\n",
    "    slide_cls_ids = [[] for i in range(num_classes)]\n",
    "    for i in range(num_classes):\n",
    "        slide_cls_ids[i] = np.where(slide_data['label'] == i)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7da0d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filter_dict={}):\n",
    "    if len(filter_dict) > 0:\n",
    "        filter_mask = np.full(len(df), True, bool)\n",
    "        # assert 'label' not in filter_dict.keys()\n",
    "        for key, val in filter_dict.items():\n",
    "            mask = df[key].isin(val)\n",
    "            filter_mask = np.logical_and(filter_mask, mask)\n",
    "        df = df[filter_mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0d17c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_prep(data, label_dict, ignore, label_col):\n",
    "    if label_col != 'label':\n",
    "        data['label'] = data[label_col].copy()\n",
    "\n",
    "    mask = data['label'].isin(ignore)\n",
    "    data = data[~mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    for i in data.index:\n",
    "        key = data.loc[i, 'label']\n",
    "        data.at[i, 'label'] = label_dict[key]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d95f1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generic_MIL_Dataset(Generic_WSI_Classification_Dataset):\n",
    "\tdef __init__(self,\n",
    "\t\tdata_dir,\n",
    "\t\t**kwargs):\n",
    "\n",
    "\t\tsuper(Generic_MIL_Dataset, self).__init__(**kwargs)\n",
    "\t\tself.data_dir = data_dir\n",
    "\t\tself.use_h5 = False\n",
    "\n",
    "\tdef load_from_h5(self, toggle):\n",
    "\t\tself.use_h5 = toggle\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tslide_id = self.slide_data['slide_id'][idx]\n",
    "\t\tlabel = self.slide_data['label'][idx]\n",
    "\t\tif type(self.data_dir) == dict:\n",
    "\t\t\tsource = self.slide_data['source'][idx]\n",
    "\t\t\tdata_dir = self.data_dir[source]\n",
    "\t\telse:\n",
    "\t\t\tdata_dir = self.data_dir\n",
    "\n",
    "\t\tif not self.use_h5:\n",
    "\t\t\tif self.data_dir:\n",
    "\t\t\t\tfull_path = os.path.join(data_dir, 'pt_files', '{}.pt'.format(slide_id))\n",
    "\t\t\t\tfeatures = torch.load(full_path)\n",
    "\t\t\t\treturn features, label\n",
    "\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn slide_id, label\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tfull_path = os.path.join(data_dir,'h5_files','{}.h5'.format(slide_id))\n",
    "\t\t\twith h5py.File(full_path,'r') as hdf5_file:\n",
    "\t\t\t\tfeatures = hdf5_file['features'][:]\n",
    "\t\t\t\tcoords = hdf5_file['coords'][:]\n",
    "\n",
    "\t\t\tfeatures = torch.from_numpy(features)\n",
    "\t\t\treturn features, label, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f9531b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generic_Split(Generic_MIL_Dataset):\n",
    "    def __init__(self, slide_data, data_dir=None, num_classes=2):\n",
    "        self.use_h5 = False\n",
    "        self.slide_data = slide_data\n",
    "        self.data_dir = data_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.slide_cls_ids = [[] for i in range(self.num_classes)]\n",
    "        for i in range(self.num_classes):\n",
    "            self.slide_cls_ids[i] = np.where(self.slide_data['label'] == i)[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slide_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d4f2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_from_df(all_splits, split_key='train'):\n",
    "    split = all_splits[split_key]\n",
    "    split = split.dropna().reset_index(drop=True)\n",
    "\n",
    "    if len(split) > 0:\n",
    "        mask = slide_data['slide_id'].isin(split.tolist())\n",
    "        df_slice = slide_data[mask].reset_index(drop=True)\n",
    "        split = Generic_Split(df_slice, data_dir=data_dir, num_classes=num_classes)\n",
    "    else:\n",
    "        split = None\n",
    "\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "04c8c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_splits(from_id=True, csv_path=None):\n",
    "\n",
    "\n",
    "    if from_id:\n",
    "        if len(train_ids) > 0:\n",
    "            train_data = slide_data.loc[train_ids].reset_index(drop=True)\n",
    "            train_split = Generic_Split(train_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            train_split = None\n",
    "\n",
    "        if len(val_ids) > 0:\n",
    "            val_data = slide_data.loc[val_ids].reset_index(drop=True)\n",
    "            val_split = Generic_Split(val_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            val_split = None\n",
    "\n",
    "        if len(self.test_ids) > 0:\n",
    "            test_data = slide_data.loc[test_ids].reset_index(drop=True)\n",
    "            test_split = Generic_Split(test_data, data_dir=data_dir, num_classes=num_classes)\n",
    "\n",
    "        else:\n",
    "            test_split = None\n",
    "\n",
    "\n",
    "    else:\n",
    "        assert csv_path\n",
    "        all_splits = pd.read_csv(csv_path, dtype=slide_data['slide_id'].dtype)  # Without \"dtype=self.slide_data['slide_id'].dtype\", read_csv() will convert all-number columns to a numerical type. Even if we convert numerical columns back to objects later, we may lose zero-padding in the process; the columns must be correctly read in from the get-go. When we compare the individual train/val/test columns to self.slide_data['slide_id'] in the get_split_from_df() method, we cannot compare objects (strings) to numbers or even to incorrectly zero-padded objects/strings. An example of this breaking is shown in https://github.com/andrew-weisman/clam_analysis/tree/main/datatype_comparison_bug-2021-12-01.\n",
    "        train_split = get_split_from_df(all_splits, 'train')\n",
    "        val_split = get_split_from_df(all_splits, 'val')\n",
    "        test_split = get_split_from_df(all_splits, 'test')\n",
    "\n",
    "    return train_split, val_split, test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025e6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9cde098c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         case_id   slide_id label\n",
      "0      patient_0    slide_0     1\n",
      "1      patient_0    slide_1     0\n",
      "2      patient_1    slide_2     1\n",
      "3      patient_2    slide_3     0\n",
      "4      patient_2    slide_4     0\n",
      "..           ...        ...   ...\n",
      "495  patient_445  slide_495     1\n",
      "496  patient_446  slide_496     0\n",
      "497  patient_447  slide_497     0\n",
      "498  patient_448  slide_498     0\n",
      "499  patient_449  slide_499     1\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(label_dict.values()))\n",
    "train_ids, val_ids, test_ids = (None, None, None)\n",
    "data_dir = None\n",
    "if not label_col:\n",
    "\tlabel_col = 'label'\n",
    "label_col = label_col\n",
    "\n",
    "slide_data = pd.read_csv(csv_path)\n",
    "slide_data = filter_df(slide_data, filter_dict)\n",
    "slide_data = df_prep(slide_data, label_dict, ignore, label_col)\n",
    "print(slide_data)\n",
    "\n",
    "###shuffle data\n",
    "if shuffle:\n",
    "\tnp.random.seed(seed)\n",
    "\tnp.random.shuffle(slide_data)\n",
    "\n",
    "slide_data = slide_data\n",
    "\n",
    "patient_data = patient_data_prep(patient_voting)\n",
    "cls_ids_prep(patient_data)\n",
    "\n",
    "# if print_info:\n",
    "# \tprint(\"label column: {}\".format(label_col))\n",
    "# \tprint(\"label dictionary: {}\".format(label_dict))\n",
    "# \tprint(\"number of classes: {}\".format(num_classes))\n",
    "# \tprint(\"slide-level counts: \", '\\n', slide_data['label'].value_counts(sort = False))\n",
    "# \tfor i in range(num_classes):\n",
    "# \t\tprint('Patient-LVL; Number of samples registered in class %d: %d' % (i, patient_cls_ids[i].shape[0]))\n",
    "# \t\tprint('Slide-LVL; Number of samples registered in class %d: %d' % (i, slide_cls_ids[i].shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f16b382e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9416/996929949.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplit_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslide_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slide_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9416/996929949.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msplit_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslide_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msplit_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslide_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'slide_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "split_datasets = slide_data\n",
    "splits = [split_datasets[i].slide_data['slide_id'] for i in range(len(split_datasets))]\n",
    "\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "49d9eff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 1, 1, 2])\n",
      "torch.Size([24, 1, 2])\n",
      "tensor([18, 13, 14, 15, 16, 17, 21, 23])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logits = torch.rand([24, 1, 1, 2])\n",
    "top_k = 8\n",
    "\n",
    "y_probs = F.softmax(logits, dim = 1)\n",
    "print(y_probs.shape)\n",
    "print(y_probs[:, 0].shape)\n",
    "top_instance_idx = torch.topk(y_probs[:, 0], top_k, dim=0)[1].view(8,2)[:,0]\n",
    "print(top_instance_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29005e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.rand([1, 2, 4, 8, 16])\n",
    "\n",
    "b = a.view(16,-1)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f043dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # top_instance_idx = torch.topk(y_probs[:, 0], self.top_k, dim=0)[1].view(1,)self.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4ee39917",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected target size (1, 2), got torch.Size([1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7307/1127118029.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clam/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m             raise ValueError('Expected target size {}, got {}'.format(\n\u001b[0;32m-> 1848\u001b[0;31m                 out_size, target.size()))\n\u001b[0m\u001b[1;32m   1849\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (1, 2), got torch.Size([1, 1])"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "a = torch.Tensor([[[5., 7.]]])\n",
    "b = torch.Tensor([[0.]]).long()\n",
    "\n",
    "loss = loss_fn(a, b)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bddc211",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39642/19565222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m19.3550\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m58.1746\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[[[-19.3550,  58.1746]]]])\n",
    "\n",
    "b = F.softmax(a, dim=3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0f1f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([0.9355, 0.8572, 0.7352, 0.6882, 0.6605, 0.6605, 0.6472, 0.6440]),\n",
      "indices=tensor([18,  8,  5,  1,  4, 15, 23, 11]))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "index_select() received an invalid combination of arguments - got (Tensor, index=torch.return_types.topk, dim=int), but expected one of:\n * (Tensor input, name dim, Tensor index, Tensor out)\n * (Tensor input, int dim, Tensor index, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39642/1250551766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_instance_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtop_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_instance_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: index_select() received an invalid combination of arguments - got (Tensor, index=torch.return_types.topk, dim=int), but expected one of:\n * (Tensor input, name dim, Tensor index, Tensor out)\n * (Tensor input, int dim, Tensor index, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "h = torch.rand([24, 10])\n",
    "a = torch.rand([24, ])\n",
    "top_k = 8\n",
    "\n",
    "top_instance_idx = torch.topk(a, top_k, dim=0)#[1]#.view(8,2)[:,0]\n",
    "print(top_instance_idx)\n",
    "\n",
    "top_p = torch.index_select(h, dim=0, index=top_instance_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "clam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
