{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f162b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import pdb\n",
    "import os\n",
    "import math\n",
    "\n",
    "# internal imports\n",
    "from utils.file_utils import save_pkl, load_pkl\n",
    "from utils.utils import *\n",
    "from utils.core_utils import train\n",
    "from datasets.dataset_generic import Generic_WSI_Classification_Dataset, Generic_MIL_Dataset\n",
    "\n",
    "# pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, sampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ee98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # create results directory if necessary\n",
    "    if not os.path.isdir(args.results_dir):\n",
    "        os.mkdir(args.results_dir)\n",
    "\n",
    "    if args.k_start == -1:\n",
    "        start = 0\n",
    "    else:\n",
    "        start = args.k_start\n",
    "    if args.k_end == -1:\n",
    "        end = args.k\n",
    "    else:\n",
    "        end = args.k_end\n",
    "\n",
    "    all_test_auc = []\n",
    "    all_val_auc = []\n",
    "    all_test_acc = []\n",
    "    all_val_acc = []\n",
    "    folds = np.arange(start, end)\n",
    "    for i in folds:\n",
    "        seed_torch(args.seed)\n",
    "        train_dataset, val_dataset, test_dataset = dataset.return_splits(from_id=False, \n",
    "                csv_path='{}/splits_{}.csv'.format(args.split_dir, i))\n",
    "        \n",
    "        datasets = (train_dataset, val_dataset, test_dataset)\n",
    "        results, test_auc, val_auc, test_acc, val_acc  = train(datasets, i, args)\n",
    "        all_test_auc.append(test_auc)\n",
    "        all_val_auc.append(val_auc)\n",
    "        all_test_acc.append(test_acc)\n",
    "        all_val_acc.append(val_acc)\n",
    "        #write results to pkl\n",
    "        filename = os.path.join(args.results_dir, 'split_{}_results.pkl'.format(i))\n",
    "        save_pkl(filename, results)\n",
    "\n",
    "    final_df = pd.DataFrame({'folds': folds, 'test_auc': all_test_auc, \n",
    "        'val_auc': all_val_auc, 'test_acc': all_test_acc, 'val_acc' : all_val_acc})\n",
    "\n",
    "    if len(folds) != args.k:\n",
    "        save_name = 'summary_partial_{}_{}.csv'.format(start, end)\n",
    "    else:\n",
    "        save_name = 'summary.csv'\n",
    "    final_df.to_csv(os.path.join(args.results_dir, save_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3913bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic training settings\n",
    "parser = argparse.ArgumentParser(description='Configurations for WSI Training')\n",
    "parser.add_argument('--data_root_dir', type=str, default=None, \n",
    "                    help='data directory')\n",
    "parser.add_argument('--max_epochs', type=int, default=200,\n",
    "                    help='maximum number of epochs to train (default: 200)')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='learning rate (default: 0.0001)')\n",
    "parser.add_argument('--label_frac', type=float, default=1.0,\n",
    "                    help='fraction of training labels (default: 1.0)')\n",
    "parser.add_argument('--reg', type=float, default=1e-5,\n",
    "                    help='weight decay (default: 1e-5)')\n",
    "parser.add_argument('--seed', type=int, default=1, \n",
    "                    help='random seed for reproducible experiment (default: 1)')\n",
    "parser.add_argument('--k', type=int, default=10, help='number of folds (default: 10)')\n",
    "parser.add_argument('--k_start', type=int, default=-1, help='start fold (default: -1, last fold)')\n",
    "parser.add_argument('--k_end', type=int, default=-1, help='end fold (default: -1, first fold)')\n",
    "parser.add_argument('--results_dir', default='./results', help='results directory (default: ./results)')\n",
    "parser.add_argument('--split_dir', type=str, default=None, \n",
    "                    help='manually specify the set of splits to use, ' \n",
    "                    +'instead of infering from the task and label_frac argument (default: None)')\n",
    "parser.add_argument('--log_data', action='store_true', default=False, help='log data using tensorboard')\n",
    "parser.add_argument('--testing', action='store_true', default=False, help='debugging tool')\n",
    "parser.add_argument('--early_stopping', action='store_true', default=False, help='enable early stopping')\n",
    "parser.add_argument('--opt', type=str, choices = ['adam', 'sgd'], default='adam')\n",
    "parser.add_argument('--drop_out', action='store_true', default=False, help='enabel dropout (p=0.25)')\n",
    "parser.add_argument('--bag_loss', type=str, choices=['svm', 'ce'], default='ce',\n",
    "                     help='slide-level classification loss function (default: ce)')\n",
    "parser.add_argument('--model_type', type=str, choices=['clam_sb', 'clam_mb', 'mil'], default='clam_sb', \n",
    "                    help='type of model (default: clam_sb, clam w/ single attention branch)')\n",
    "parser.add_argument('--exp_code', type=str, help='experiment code for saving results')\n",
    "parser.add_argument('--weighted_sample', action='store_true', default=False, help='enable weighted sampling')\n",
    "parser.add_argument('--model_size', type=str, choices=['small', 'big'], default='small', help='size of model, does not affect mil')\n",
    "parser.add_argument('--task', type=str, choices=['task_1_tumor_vs_normal',  'task_2_tumor_subtyping'])\n",
    "### CLAM specific options\n",
    "parser.add_argument('--no_inst_cluster', action='store_true', default=False,\n",
    "                     help='disable instance-level clustering')\n",
    "parser.add_argument('--inst_loss', type=str, choices=['svm', 'ce', None], default=None,\n",
    "                     help='instance-level clustering loss function (default: None)')\n",
    "parser.add_argument('--subtyping', action='store_true', default=False, \n",
    "                     help='subtyping problem')\n",
    "parser.add_argument('--bag_weight', type=float, default=0.7,\n",
    "                    help='clam: weight coefficient for bag-level loss (default: 0.7)')\n",
    "parser.add_argument('--B', type=int, default=8, help='numbr of positive/negative patches to sample for clam')\n",
    "args = parser.parse_args()\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_torch(seed=7):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(args.seed)\n",
    "\n",
    "encoding_size = 1024\n",
    "settings = {'num_splits': args.k, \n",
    "            'k_start': args.k_start,\n",
    "            'k_end': args.k_end,\n",
    "            'task': args.task,\n",
    "            'max_epochs': args.max_epochs, \n",
    "            'results_dir': args.results_dir, \n",
    "            'lr': args.lr,\n",
    "            'experiment': args.exp_code,\n",
    "            'reg': args.reg,\n",
    "            'label_frac': args.label_frac,\n",
    "            'bag_loss': args.bag_loss,\n",
    "            'seed': args.seed,\n",
    "            'model_type': args.model_type,\n",
    "            'model_size': args.model_size,\n",
    "            \"use_drop_out\": args.drop_out,\n",
    "            'weighted_sample': args.weighted_sample,\n",
    "            'opt': args.opt}\n",
    "\n",
    "if args.model_type in ['clam_sb', 'clam_mb']:\n",
    "   settings.update({'bag_weight': args.bag_weight,\n",
    "                    'inst_loss': args.inst_loss,\n",
    "                    'B': args.B})\n",
    "\n",
    "print('\\nLoad Dataset')\n",
    "\n",
    "\n",
    "if args.task == 'task_fungal_vs_nonfungal':\n",
    "    args.n_classes=2\n",
    "    dataset = Generic_MIL_Dataset(csv_path = 'dataset_csv/fungal_vs_nonfungal.csv',\n",
    "                            data_dir= os.path.join(args.data_root_dir, 'fungal_vs_nonfungal_resnet_features'),\n",
    "                            shuffle = False, \n",
    "                            seed = args.seed, \n",
    "                            print_info = True,\n",
    "                            label_dict = {'nonfungal':0, 'fungal':1},\n",
    "                            patient_strat=False,\n",
    "                            ignore=[])\n",
    "\n",
    "elif args.task == 'task_1_tumor_vs_normal':\n",
    "    args.n_classes=2\n",
    "    dataset = Generic_MIL_Dataset(csv_path = 'dataset_csv/tumor_vs_normal_dummy_clean.csv',\n",
    "                            data_dir= os.path.join(args.data_root_dir, 'tumor_vs_normal_resnet_features'),\n",
    "                            shuffle = False, \n",
    "                            seed = args.seed, \n",
    "                            print_info = True,\n",
    "                            label_dict = {'normal_tissue':0, 'tumor_tissue':1},\n",
    "                            patient_strat=False,\n",
    "                            ignore=[])\n",
    "\n",
    "elif args.task == 'task_2_tumor_subtyping':\n",
    "    args.n_classes=3\n",
    "    dataset = Generic_MIL_Dataset(csv_path = 'dataset_csv/tumor_subtyping_dummy_clean.csv',\n",
    "                            data_dir= os.path.join(args.data_root_dir, 'tumor_subtyping_resnet_features'),\n",
    "                            shuffle = False, \n",
    "                            seed = args.seed, \n",
    "                            print_info = True,\n",
    "                            label_dict = {'subtype_1':0, 'subtype_2':1, 'subtype_3':2},\n",
    "                            patient_strat= False,\n",
    "                            ignore=[])\n",
    "\n",
    "    if args.model_type in ['clam_sb', 'clam_mb']:\n",
    "        assert args.subtyping \n",
    "        \n",
    "else:\n",
    "    raise NotImplementedError\n",
    "    \n",
    "if not os.path.isdir(args.results_dir):\n",
    "    os.mkdir(args.results_dir)\n",
    "\n",
    "args.results_dir = os.path.join(args.results_dir, str(args.exp_code) + '_s{}'.format(args.seed))\n",
    "if not os.path.isdir(args.results_dir):\n",
    "    os.mkdir(args.results_dir)\n",
    "\n",
    "if args.split_dir is None:\n",
    "    args.split_dir = os.path.join('splits', args.task+'_{}'.format(int(args.label_frac*100)))\n",
    "else:\n",
    "    args.split_dir = os.path.join('splits', args.split_dir)\n",
    "\n",
    "print('split_dir: ', args.split_dir)\n",
    "assert os.path.isdir(args.split_dir)\n",
    "\n",
    "settings.update({'split_dir': args.split_dir})\n",
    "\n",
    "\n",
    "with open(args.results_dir + '/experiment_{}.txt'.format(args.exp_code), 'w') as f:\n",
    "    print(settings, file=f)\n",
    "f.close()\n",
    "\n",
    "print(\"################# Settings ###################\")\n",
    "for key, val in settings.items():\n",
    "    print(\"{}:  {}\".format(key, val))        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main(args)\n",
    "    print(\"finished!\")\n",
    "    print(\"end script\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam",
   "language": "python",
   "name": "clam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
